{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c284b90",
   "metadata": {},
   "source": [
    "Fetch video comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13f92e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIzaSyBpA5J9hmHIaLUXfsTzVIbFO5fRUFXHHls\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # loads .env into environment\n",
    "\n",
    "YOUTUBE_API_KEY = os.getenv(\"YOUTUBE_API_KEY\")\n",
    "print(YOUTUBE_API_KEY)\n",
    "\n",
    "if not YOUTUBE_API_KEY:\n",
    "    raise ValueError(\"YOUTUBE_API_KEY not found in .env file\")\n",
    "\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "def get_youtube_comments( video_id: str, max_comments: int = None):\n",
    "    \"\"\"\n",
    "    Fetch comments from a YouTube video using YouTube Data API v3.\n",
    "\n",
    "    :param api_key: YouTube Data API key\n",
    "    :param video_id: YouTube video ID\n",
    "    :param max_comments: Optional limit on number of comments\n",
    "    :return: List of comment dictionaries\n",
    "    \"\"\"\n",
    "\n",
    "    youtube = build(\"youtube\", \"v3\", developerKey=YOUTUBE_API_KEY)\n",
    "\n",
    "    comments = []\n",
    "    next_page_token = None\n",
    "\n",
    "    while True:\n",
    "        request = youtube.commentThreads().list(\n",
    "            part=\"snippet\",\n",
    "            videoId=video_id,\n",
    "            maxResults=100,\n",
    "            textFormat=\"plainText\",\n",
    "            pageToken=next_page_token,\n",
    "            order=\"time\",  \n",
    "        )\n",
    "\n",
    "        response = request.execute()\n",
    "\n",
    "        for item in response[\"items\"]:\n",
    "            snippet = item[\"snippet\"][\"topLevelComment\"][\"snippet\"]\n",
    "            \"\"\"\n",
    "            comments.append({\n",
    "                \"author\": snippet[\"authorDisplayName\"],\n",
    "                \"comment\": snippet[\"textDisplay\"],\n",
    "                \"likes\": snippet[\"likeCount\"],\n",
    "                \"published_at\": snippet[\"publishedAt\"]\n",
    "            })\n",
    "            \"\"\"\n",
    "\n",
    "            comments.append(\n",
    "                 snippet[\"textDisplay\"]\n",
    "            )\n",
    "            if max_comments and len(comments) >= max_comments:\n",
    "                return comments\n",
    "\n",
    "        next_page_token = response.get(\"nextPageToken\")\n",
    "        if not next_page_token:\n",
    "            break\n",
    "\n",
    "    return comments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "add72d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hi guys, Nitish here! I just wrote a new blog ‚Äî ‚ÄúHow Google Built Its AI Empire‚Äù ‚Äî and trust me, some of the behind-the-scenes stories will surprise you. \\nGive it a read when you get a minute: https://learnwith.campusx.in/blog/how-google-built-its-ai-empire\\n\\nWould love to hear what feedback you have! üòä', 'notes', 'Completed 6 Jan', \"Arey isme agentic kaha hei ?.Only the tool calling is agentic wether should I call a rag toolor not it's not agentic rag\", \"Sir, you're not only the best when it comes to teaching anything related to AI(and its sub-domains), but you're also a role model for how passionate a teacher should be for teaching. Thank you for taking up this profession of teaching sir‚ù§\", 'Iove from haryana', 'thank you so much sirüôè', 'dont hurry, atleast teach whatever new code you are writing atleast explain that, otherwise y people will see the video they directly ask chat gpt to produce the code as your tell to ask chat gpt to explain', \"Nitish sir olease don't hurry in completing the course. Its okk if videos become long and you make videos at your total convenience, but please teach everything.\", 'Iske pichy ki baqi videos k link dy dain please', 'please shoot video on build Rag AI Agents i requestüôèüôèüôèüôèüôèüôèüôèüôèüôè@campusx', 'SIR NEXT VIDEO KAB AAEGA', 'SIR NEXT VIDEO KAB AAEGA', 'Is this final lecture or more will come', '@campusx-official  sir could you please add the notes for this playlist as well . This would be really helpful . Thanks', 'please sir next video ?', 'Please add the HITL concept also. I want to add HITL to make users write an essay after we give them a topic, and after receiving the essay, we continue the rest of the evaluation process', 'Thanks for the video. \\nWaiting for some advanced RAG videos like GraphRAG or hybrid RAG with smart ingestion in some enterprise setting. Also involving relevant chat history in each prompt/query.', '@Nitish sir, I learned a lot from this playlist.‚ù§', 'great video sir and waiting for new video', 'great video sir and waiting for new video ............................................', 'Sir please continue the MLOps series', 'Amazing session! üî• The way you explained RAG and Agentic AI using LangGraph is super clear and practical. \\nLoving this series so far ‚Äì it‚Äôs exactly what I was looking for. üôå\\nPlease complete and upload the upcoming videos of this LangGraph playlist soon ‚Äî I‚Äôm genuinely excited to follow the entire playlist till the end.\\nA humble request from a enthusiastic learner üôèüî•', 'Thanks', 'Sir once this is done please start with rag, fine tuning llms, hallucinations and llm concepts please', 'Sir, please build a multimodal RAG chatbot that can process images, graphs, and tables.', 'AI Engineer roadmap?', 'Sir what is the secret of your consistency üò≠', 'Great video on Rag, just one thing could be added is different chunking strategies.', 'You are a great teacher of AI', 'My final yr project is based on RAG. Inspired by Nitish sir. will post its repo link after its completed', 'Hii Sir please do a video on googles now research paper \"Nested Learning\" they are saying it\\'s kind of Attention all you need 2.0 , this nested learning is the backbone of Gemini 3 which out performed all the models', 'would be great if u could switch to dark mode instead of whiteboard', 'Dear sir, kindly make video (playlist) on Kolmogorov-Arnold Networks (KANs), only you can make us understand in right way. Thanks in Advance!', 'i am your big fan sir!', 'Sr pytourch ki play list complete karo na', 'sir will you make a playlist around LLM fine tuning where we fine tune different types of text to text, text to image and image to image models locally? if yes then when?', 'One question on that \\n\\nin streamlit, if you ask two questions one by one then it loads the rag file again and as a result of this time of processing increaseing', 'Was waiting since long', '@nitish thanks for great videos!!. Can you help us with implementing cache as well. Both in RAG and SQL database chatbot as well ?', 'Great content', 'Really very useful!', 'Please also cover deep and ambient agents later on', 'Sir I have some short but very important question : \\n1. Should we learn react/next js for frontend to get AI Engineer Job as streamlit it just for demo \\n2. Should we continue practicing / experimenting traditional ML/DL even we are learning on Agentic AI with your lectures as I have not worked on ML/DL from 2 months \\n3. Should we learn all concepts of FastAPI & read all documentation of Vector DB like qdrant for production using LLMs like claude', \"In Love with this playlist, honestly your teaching style is like a drug & I'm addicted to it. Would love more videos soon üòç.\\n\\nThank you sir and please keep up the good work\", 'üî•üî•üî• very useful', '‚ù§‚ù§', 'Sir if we want to build Conversation BI using initial logic of chatbot', 'Hi Sir,\\nI wanted your guidance regarding project building for placements.\\n\\nI currently have hands-on experience with:\\n\\nLangChain and LangGraph\\n\\nDocker and FastAPI\\n\\nMCP server basics\\n\\nToy RAG chatbots (e.g., Flipkart FAQ, Mamaearth FAQ)\\n\\nA small AI agent with 4‚Äì5 tools\\n\\n\\nSince I want to target roles in GenAI/LLM engineering, I wanted to ask:\\n\\n1. What type of projects should I focus on building now to make my profile strong for recruiters?\\n2. As a fresher in GenAI, what do recruiters expect to see in our projects?\\n3. Are there any specific real-world style projects or problem statements you recommend?\\n\\nYour suggestions will help me build the right kind of portfolio for internships and placements. \\nThank you!', 'üéâüéâ', 'I love Campus X, mostly video comes when I am working on same subject. Thank you Sir Nitish. I almost became addicted to your teaching style and videos.', 'what about Types of RAGs, Agentic RAG, Multimodal RAGs and all other details about RAG Sir ? Would love to get some more detailed insight about the future roadmap about RAG. please let me know. it would be really very helpfull. Thanks a lot for all your help and guidance. The videos are actually very detailed and helpful.', 'Sir aj apny 6 courses announcement krni thi, waiting for your announcement video', '‚ù§‚ù§‚ù§‚ù§‚ù§', 'Please start playlist on Fine-tuning', 'Just ydd kiya aur video hazir üòÖüòÇüòÇ', '‚ù§‚ù§‚ù§‚ù§‚ù§', '‚ô•‚ô•‚ô•First Comment Without seeing this Video, One more jemsüíé has been added‚ù§‚ù§‚ù§']\n"
     ]
    }
   ],
   "source": [
    "print(get_youtube_comments(\"E1qP9Xsnmik\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d216343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from IPython.display import Markdown, display\n",
    "load_dotenv(override=True)\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "MODEL = \"gpt-4.1-mini\"\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9385aa2b",
   "metadata": {},
   "outputs": [
    {
     "ename": "HttpError",
     "evalue": "<HttpError 404 when requesting https://youtube.googleapis.com/youtube/v3/commentThreads?part=snippet&videoId=AIzaSyBpA5J9hmHIaLUXfsTzVIbFO5fRUFXHHls&maxResults=100&textFormat=plainText&order=time&key=AIzaSyBpA5J9hmHIaLUXfsTzVIbFO5fRUFXHHls&alt=json returned \"The video identified by the <code><a href=\"/youtube/v3/docs/commentThreads/list#videoId\">videoId</a></code> parameter could not be found.\". Details: \"[{'message': 'The video identified by the <code><a href=\"/youtube/v3/docs/commentThreads/list#videoId\">videoId</a></code> parameter could not be found.', 'domain': 'youtube.commentThread', 'reason': 'videoNotFound', 'location': 'videoId', 'locationType': 'parameter'}]\">",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHttpError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m openai.api_key = os.getenv(\u001b[33m\"\u001b[39m\u001b[33mOPENAI_API_KEY\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m comments_list = \u001b[43mget_youtube_comments\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mAIzaSyBpA5J9hmHIaLUXfsTzVIbFO5fRUFXHHls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mUrMnOp2N9Kw\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Convert the list to string for prompt injection\u001b[39;00m\n\u001b[32m      7\u001b[39m comments_str = \u001b[38;5;28mstr\u001b[39m(comments_list)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 39\u001b[39m, in \u001b[36mget_youtube_comments\u001b[39m\u001b[34m(video_id, max_comments)\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m     30\u001b[39m     request = youtube.commentThreads().list(\n\u001b[32m     31\u001b[39m         part=\u001b[33m\"\u001b[39m\u001b[33msnippet\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     32\u001b[39m         videoId=video_id,\n\u001b[32m   (...)\u001b[39m\u001b[32m     36\u001b[39m         order=\u001b[33m\"\u001b[39m\u001b[33mtime\u001b[39m\u001b[33m\"\u001b[39m,  \n\u001b[32m     37\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     response = \u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m response[\u001b[33m\"\u001b[39m\u001b[33mitems\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m     42\u001b[39m         snippet = item[\u001b[33m\"\u001b[39m\u001b[33msnippet\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtopLevelComment\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33msnippet\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/youtube-comments-analyzer/youtube-comments-analyzer/.venv/lib/python3.11/site-packages/googleapiclient/_helpers.py:130\u001b[39m, in \u001b[36mpositional.<locals>.positional_decorator.<locals>.positional_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m positional_parameters_enforcement == POSITIONAL_WARNING:\n\u001b[32m    129\u001b[39m         logger.warning(message)\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/youtube-comments-analyzer/youtube-comments-analyzer/.venv/lib/python3.11/site-packages/googleapiclient/http.py:938\u001b[39m, in \u001b[36mHttpRequest.execute\u001b[39m\u001b[34m(self, http, num_retries)\u001b[39m\n\u001b[32m    936\u001b[39m     callback(resp)\n\u001b[32m    937\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m resp.status >= \u001b[32m300\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m938\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HttpError(resp, content, uri=\u001b[38;5;28mself\u001b[39m.uri)\n\u001b[32m    939\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.postproc(resp, content)\n",
      "\u001b[31mHttpError\u001b[39m: <HttpError 404 when requesting https://youtube.googleapis.com/youtube/v3/commentThreads?part=snippet&videoId=AIzaSyBpA5J9hmHIaLUXfsTzVIbFO5fRUFXHHls&maxResults=100&textFormat=plainText&order=time&key=AIzaSyBpA5J9hmHIaLUXfsTzVIbFO5fRUFXHHls&alt=json returned \"The video identified by the <code><a href=\"/youtube/v3/docs/commentThreads/list#videoId\">videoId</a></code> parameter could not be found.\". Details: \"[{'message': 'The video identified by the <code><a href=\"/youtube/v3/docs/commentThreads/list#videoId\">videoId</a></code> parameter could not be found.', 'domain': 'youtube.commentThread', 'reason': 'videoNotFound', 'location': 'videoId', 'locationType': 'parameter'}]\">"
     ]
    }
   ],
   "source": [
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "comments_list = get_youtube_comments(\"E1qP9Xsnmik\")\n",
    "\n",
    "# Convert the list to string for prompt injection\n",
    "comments_str = str(comments_list)\n",
    "\n",
    "# System message defines role and context for the model\n",
    "system_message = {\n",
    "    \"role\": \"system\",\n",
    "    \"content\": \"You are an expert sentiment analyst specializing in analyzing YouTube comments.\"\n",
    "}\n",
    "\n",
    "# User message includes instructions and the actual comments\n",
    "user_message = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": f\"\"\"\n",
    "I will provide a list of comments from a YouTube video. \n",
    "Your task:\n",
    "\n",
    "1. Analyze the overall sentiment of the comments (positive, neutral, negative).\n",
    "2. Based on the sentiment, give a clear recommendation: Should a new viewer watch or skip the video?\n",
    "3. Provide a short explanation for your recommendation (1-3 sentences).\n",
    "\n",
    "Here is the list of comments:\n",
    "{comments_str}\n",
    "\"\"\"\n",
    "}\n",
    "messages = [system_message, user_message]\n",
    "MODEL = \"gpt-4.1-mini\"\n",
    "# Call OpenAI's chat completion API\n",
    "response = openai.chat.completions.create(\n",
    "    model=MODEL,  # or \"gpt-4o\" depending on access\n",
    "    messages=messages,\n",
    "    temperature=0.7,\n",
    "    max_tokens=1500\n",
    ")\n",
    "\n",
    "# Print the model's response\n",
    "# Correct way to get the content\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66432f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nishapardeshi/Documents/Projects/youtube-comments-analyzer/youtube-comments-analyzer/.venv/bin/python3\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (yt-analyzer)",
   "language": "python",
   "name": "yt-analyzer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
